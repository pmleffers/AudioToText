{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='letthembreathespace.jpg' width=\"480\" height=\"370\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install numpy matplotlib scipy sklearn hmmlearn simplejson eyed3 pydub --user\n",
    "#!pip install pydub --user\n",
    "#!pip install ffmpeg --user\n",
    "#!pip install deepspeech==0.2.0a8 --user\n",
    "#!pip install sox  --user\n",
    "\n",
    "#import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "import uuid\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeech.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudiodirName = './SoundFiles'\n",
    "ModeldirName = './models'\n",
    "\n",
    "DirList=[AudiodirName,ModeldirName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  ./SoundFiles  already exists\n",
      "Directory  ./models  already exists\n"
     ]
    }
   ],
   "source": [
    "for i in DirList:\n",
    "    try:\n",
    "        # Create target Directory\n",
    "        os.mkdir(i)\n",
    "        print(\"Directory \" ,i,  \" Created \") \n",
    "    except:\n",
    "        print(\"Directory \" ,i,  \" already exists\")\n",
    "\n",
    "#os.chdir(AudiodirName)\n",
    "#print('Moved to directory',os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Audio Book and Extract it to Audio Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://www.archive.org/download//letembreathespaceversion2_1809_librivox/letembreathespaceversion2_1809_librivox_64kb_mp3.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letembreathspace_03_delrey_64kb.mp3\n",
      "Saved in location:\t ./SoundFiles\n",
      "letembreathspace_01_delrey_64kb.mp3\n",
      "Saved in location:\t ./SoundFiles\n",
      "letembreathspace_04_delrey_64kb.mp3\n",
      "Saved in location:\t ./SoundFiles\n",
      "letembreathspace_02_delrey_64kb.mp3\n",
      "Saved in location:\t ./SoundFiles\n",
      "letembreathspace_05_delrey_64kb.mp3\n",
      "Saved in location:\t ./SoundFiles\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "Save_Location=AudiodirName\n",
    "Zip_Location='./letembreathespaceversion2_1809_librivox_64kb_mp3.zip'\n",
    "#Extracting Zip File\n",
    "zip_ref = zipfile.ZipFile(Zip_Location, 'r')\n",
    "\n",
    "\n",
    "#Preview files within zip\n",
    "for name in zip_ref.namelist():\n",
    "    print('%s' % (name))\n",
    "    print('Saved in location:\\t',Save_Location)\n",
    "    \n",
    "zip_ref.extractall(Save_Location)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Audio File based on Decibal Level and Silence Time (miliseconds)\n",
    "\n",
    "*We are trying to achieve less than a minute in Audio Length for each file. This is because DeepSpeech has a difficult time parsing text to audio files larger than what it was trained on. For simplicity each seperation is restricted to less than a minute.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "sound = AudioSegment.from_file(AudiodirName+\"/letembreathspace_01_delrey_64kb.mp3\", format=\"mp3\")\n",
    "sound = sound.set_frame_rate(16000).set_channels(1)\n",
    "chunks = split_on_silence(\n",
    "    sound,\n",
    "    # split on silences longer than 1000ms (1 sec)\n",
    "    min_silence_len=1000,\n",
    "\n",
    "    # anything under -16 dBFS is considered silence\n",
    "    silence_thresh=-64, \n",
    "\n",
    "    # keep 200 ms of leading/trailing silence\n",
    "    keep_silence=200\n",
    ")\n",
    "\n",
    "# now recombine the chunks so that the parts are at least 90 sec long\n",
    "target_length = 90 * 1000\n",
    "output_chunks = [chunks[0]]\n",
    "for chunk in chunks[1:]:\n",
    "    if len(output_chunks[-1]) < target_length:\n",
    "        output_chunks[-1] += chunk\n",
    "    else:\n",
    "        # if the last output chunk is longer than the target length,\n",
    "        # we can start a new one\n",
    "        output_chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileList=[]\n",
    "for i, chunk in enumerate(chunks):\n",
    "    #print(i)\n",
    "    #print(chunk)\n",
    "    chunk.export(AudiodirName+\"/chunk{0}_16bit.wav\".format(i), format=\"wav\", bitrate=\"16k\")\n",
    "    FileList.append(AudiodirName+\"/chunk{0}_16bit.wav\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x7f7b1c3b2b70>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f7b016b00b8>,\n",
       " <pydub.audio_segment.AudioSegment at 0x7f7b016b0ba8>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_List=FileList[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling only 15 of the audio files that were split for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SoundFiles/chunk0_16bit.wav']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of audio files to be translated into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListString=''\n",
    "for i in Test_List:\n",
    "    ListString=ListString+i+' '\n",
    "    with open('audio_list.txt',\"a+\") as f:\n",
    "        f.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./SoundFiles/chunk0_16bit.wav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:  ./SoundFiles/chunk0_16bit.wav\n",
      " \n",
      "\n",
      "DeepSpeech says, \"...chaper one of lot om breethe space this is a lebrivox recording all leberhoxks recordings are in the public domain or more information nor e volunteer please visit lebri vox don orp recording by fill shon aber in the byus of louisziana...\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TextOut={}\n",
    "for _file_id in range(0,len(Test_List)): \n",
    "    # Get Audio Filename\n",
    "    vf = Test_List[_file_id]    \n",
    "    print('file: ',vf)\n",
    "    print(' ')\n",
    "    file_path,file_name = os.path.split(vf)\n",
    "#    folder_name = AudiodirName\n",
    "#    print(folder_name)\n",
    "#    try:\n",
    "#        os.makedirs(folder_name)\n",
    "#    except:\n",
    "#        print(\"Directory %s exists \\n\"%folder_name)\n",
    "                #model location                   alphabet file\n",
    "    ds = Model(ModeldirName+'/output_graph.pb', 26, 9, ModeldirName+'/alphabet.txt', 500)\n",
    "    fs, audio = wav.read(vf)\n",
    "    processed_data=ds.stt(audio,fs)\n",
    "    processed_data=ds.stt(audio.flatten(),fs)\n",
    "    TextOut[file_name]=processed_data\n",
    "    \n",
    "    try:\n",
    "        print('\\nDeepSpeech says, \"...'+str(processed_data)+'...\"\\n')\n",
    "    except:\n",
    "        print(\"print statement didn't work\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunk0_16bit.wav': 'chaper one of lot om breethe space this is a lebrivox recording all leberhoxks recordings are in the public domain or more information nor e volunteer please visit lebri vox don orp recording by fill shon aber in the byus of louisziana'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import subprocess\n",
    "#from subprocess import call\n",
    "#subprocess.call(['ffmpeg','-i','12_sec_mono_16bit.wav -f segment -segment_time 15 -c copy out%03d.wav'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ffmpeg -i 12_sec_mono_16bit.wav -f segment -segment_time 15 -c copy out%03d.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sound = AudioSegment.from_file(\"12_sec_mono_16bit.wav\", format=\"wav\")\n",
    "#play(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t1 = t1 * 60000 #Works in milliseconds, 60000 in 1 minute\n",
    "#t2 = t2 * 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newAudio = AudioSegment.from_wav(\"17401-chap_10_mono_16bit.wav\")\n",
    "#newAudio = newAudio[t1:t2]\n",
    "#newAudio.export('newSong.wav', format=\"wav\") #Exports to a wav file in the current path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_list = []\n",
    "# open file and read the content in a list\n",
    "#with open('audio_list.txt', 'r') as filehandle:  \n",
    "#    file_list = [current_file.rstrip() for current_file in filehandle.readlines()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
